{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import metal\n",
    "import os\n",
    "# Import other dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "os.environ['METALHOME'] = '/dfs/scratch1/saelig/slicing/metal/'\n",
    "# Set random seed for notebook\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "Here, the train/test split was defined in the dataset. We then split the train set into a train/valid (see next cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, transform\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "DATASET_DIR = '/dfs/scratch1/saelig/slicing/CUB_200_2011/'\n",
    "IMAGES_DIR = os.path.join(DATASET_DIR, 'images')\n",
    "\n",
    "#Size of eac\n",
    "image_list = np.loadtxt(os.path.join(DATASET_DIR, 'images.txt'), dtype=str)\n",
    "train_test_split = np.loadtxt(os.path.join(DATASET_DIR, 'train_test_split.txt'), dtype=int)\n",
    "labels = np.loadtxt(os.path.join(DATASET_DIR, 'image_class_labels.txt'), dtype=int)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "#image size (332, 500, 3)\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "tt = transforms.ToTensor()\n",
    "train_valid_ids = []\n",
    "test_ids = []\n",
    "\n",
    "for image_id, image_file in image_list:\n",
    "    image_id = int(image_id)\n",
    "    image_data = io.imread(os.path.join(IMAGES_DIR, image_file))\n",
    "    image_data = transform.resize(image_data, (224,224,3)) #resize all images to 224x224\n",
    "    image_data = normalize(tt(image_data).type(torch.float32)) #make channel dim first\n",
    "    label = labels[image_id - 1][1] #Keep 1 the first class since 0 is used for abstain\n",
    "    if train_test_split[image_id - 1][1] == 1: #put in train\n",
    "        train_valid_ids.append(image_id)\n",
    "        X.append(image_data)\n",
    "        Y.append(label)\n",
    "    else: #put in test\n",
    "        test_ids.append(image_id)\n",
    "        X_test.append(image_data)\n",
    "        Y_test.append(label)\n",
    "\n",
    "train_valid_ids = torch.tensor(train_valid_ids)\n",
    "test_ids = torch.tensor(test_ids)\n",
    "X_train = torch.stack(X)\n",
    "Y_train = np.array(Y)\n",
    "X_test = torch.stack(X_test)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's convert all the data to tensors, and create a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   1   1 ... 200 200 200]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)\n",
    "\n",
    "from metal.utils import split_data\n",
    "\n",
    "(X_train, X_valid), (Y_train, Y_valid), (train_ids, valid_ids) = split_data(X_train, Y_train, train_valid_ids, splits=[0.8,0.2], seed=SEED)\n",
    "\n",
    "# X_train, X_valid, X_test = torch.tensor(X_train), torch.tensor(X_valid), torch.tensor(X_test)\n",
    "Y_train, Y_valid, Y_test = torch.tensor(Y_train), torch.tensor(Y_valid), torch.tensor(Y_test)\n",
    "\n",
    "# X_train = X_train.permute(0,3,1,2)\n",
    "# X_valid = X_valid.permute(0,3,1,2)\n",
    "# X_test = X_test.permute(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4795 1199 5794\n"
     ]
    }
   ],
   "source": [
    "# torch.save(train_ids, 'train_image_ids.pt')\n",
    "# torch.save(valid_ids, 'valid_image_ids.pt')\n",
    "# torch.save(test_ids, 'test_image_ids.pt')\n",
    "# torch.save(Y_train, 'Y_train.pt')\n",
    "# torch.save(X_train, 'X_train.pt')\n",
    "# torch.save(X_valid, 'X_valid.pt')\n",
    "# torch.save(Y_valid, 'Y_valid.pt')\n",
    "# torch.save(X_test, 'X_test.pt')\n",
    "# torch.save(Y_test, 'Y_test.pt')\n",
    "\n",
    "print(len(Y_train), len(Y_valid), len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a task. Use a resnet18 for now as our input model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchvision.models.resnet import *\n",
    "from metal.mmtl.slicing.tasks import MultiClassificationTask\n",
    "from metal.mmtl.metal_model import MetalModel \n",
    "from resnet import *\n",
    "\n",
    "resnet_model = resnet18(num_classes=200, use_as_feature_extractor=True).float().cuda()\n",
    "\n",
    "task0 = MultiClassificationTask(\n",
    "    name='BirdClassificationTask', \n",
    "    input_module=resnet_model,\n",
    "    head_module=resnet_model.fc\n",
    ")\n",
    "tasks = [task0]\n",
    "model = MetalModel(tasks, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create payload abstraction for our train/valid/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Payload(Payload0_train: labels_to_tasks=[{'labels': 'BirdClassificationTask'}], split=train),\n",
      " Payload(Payload1_valid: labels_to_tasks=[{'labels': 'BirdClassificationTask'}], split=valid),\n",
      " Payload(Payload2_test: labels_to_tasks=[{'labels': 'BirdClassificationTask'}], split=test)]\n",
      "<metal.mmtl.data.MmtlDataLoader object at 0x7f8ded8f7390>\n"
     ]
    }
   ],
   "source": [
    "from metal.mmtl.payload import Payload\n",
    "from pprint import pprint\n",
    "\n",
    "payloads = []\n",
    "splits = [\"train\", \"valid\", \"test\"]\n",
    "X_splits = X_train, X_valid, X_test\n",
    "Y_splits = Y_train, Y_valid, Y_test\n",
    "\n",
    "for i in range(3):\n",
    "    payload_name = f\"Payload{i}_{splits[i]}\"\n",
    "    task_name = task0.name\n",
    "    #print(X_splits[i].shape)\n",
    "    if splits[i] == 'train': #shuffle while training\n",
    "        payload = Payload.from_tensors(payload_name, {'data': X_splits[i]}, {'labels' : Y_splits[i]}, task_name, splits[i], shuffle=True, batch_size=32)\n",
    "    else:\n",
    "        payload = Payload.from_tensors(payload_name, {'data': X_splits[i]}, {'labels' : Y_splits[i]}, task_name, splits[i], batch_size=32)\n",
    "    #payload = Payload.from_tensors(payload_name, X_splits[i], Y_splits[i], task_name, splits[i], batch_size=32)\n",
    "    payloads.append(payload)\n",
    "\n",
    "pprint(payloads)\n",
    "print(payloads[0].data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIG:  {'verbose': True, 'seed': 671085, 'commit_hash': None, 'ami': None, 'progress_bar': False, 'n_epochs': 30, 'l2': 0.0, 'grad_clip': 1.0, 'optimizer_config': {'optimizer': 'adam', 'optimizer_common': {'lr': 0.001}, 'sgd_config': {'momentum': 0.9}, 'adam_config': {'betas': (0.9, 0.999)}, 'rmsprop_config': {}}, 'lr_scheduler': 'reduce_on_plateau', 'lr_scheduler_config': {'warmup_steps': 0.0, 'warmup_unit': 'epochs', 'min_lr': 1e-06, 'exponential_config': {'gamma': 0.999}, 'plateau_config': {'factor': 0.5, 'patience': 10, 'threshold': 0.0001}}, 'metrics_config': {'task_metrics': [], 'trainer_metrics': ['model/valid/all/loss'], 'aggregate_metric_fns': [], 'max_valid_examples': 0, 'valid_split': 'valid', 'test_split': 'test'}, 'task_scheduler': 'proportional', 'logger': True, 'logger_config': {'log_unit': 'epochs', 'log_every': 2, 'score_every': -1.0, 'log_lr': True}, 'writer': None, 'writer_config': {'log_dir': '/dfs/scratch1/saelig/slicing/metal//logs', 'run_dir': None, 'run_name': None, 'writer_metrics': []}, 'checkpoint': True, 'checkpoint_tasks': False, 'checkpoint_cleanup': True, 'checkpoint_config': {'checkpoint_every': 2, 'checkpoint_best': True, 'checkpoint_metric': 'BirdClassificationTask/Payload1_valid/labels/accuracy', 'checkpoint_metric_mode': 'max', 'checkpoint_dir': None, 'checkpoint_runway': 0}}\n",
      "Beginning train loop.\n",
      "Expecting a total of approximately 4800 examples and 150 batches per epoch from 1 payload(s) in the train split.\n",
      "[2.0 epo]: BirdClassificationTask:[Payload0_train/labels/loss=5.28e+00, Payload1_valid/labels/accuracy=1.33e-02] model:[train/all/loss=5.28e+00, train/all/lr=1.00e-03, valid/all/loss=5.51e+00]\n",
      "Saving model at iteration 2.00 with best (max) score BirdClassificationTask/Payload1_valid/labels/accuracy=0.013\n",
      "[4.0 epo]: BirdClassificationTask:[Payload0_train/labels/loss=4.81e+00, Payload1_valid/labels/accuracy=3.00e-02] model:[train/all/loss=4.81e+00, train/all/lr=1.00e-03, valid/all/loss=4.84e+00]\n",
      "Saving model at iteration 4.00 with best (max) score BirdClassificationTask/Payload1_valid/labels/accuracy=0.030\n",
      "[6.0 epo]: BirdClassificationTask:[Payload0_train/labels/loss=4.37e+00, Payload1_valid/labels/accuracy=5.17e-02] model:[train/all/loss=4.37e+00, train/all/lr=1.00e-03, valid/all/loss=4.56e+00]\n",
      "Saving model at iteration 6.00 with best (max) score BirdClassificationTask/Payload1_valid/labels/accuracy=0.052\n",
      "[8.0 epo]: BirdClassificationTask:[Payload0_train/labels/loss=3.97e+00, Payload1_valid/labels/accuracy=7.59e-02] model:[train/all/loss=3.97e+00, train/all/lr=1.00e-03, valid/all/loss=4.23e+00]\n",
      "Saving model at iteration 8.00 with best (max) score BirdClassificationTask/Payload1_valid/labels/accuracy=0.076\n",
      "[10.0 epo]: BirdClassificationTask:[Payload0_train/labels/loss=3.54e+00, Payload1_valid/labels/accuracy=1.05e-01] model:[train/all/loss=3.54e+00, train/all/lr=1.00e-03, valid/all/loss=4.16e+00]\n",
      "Saving model at iteration 10.00 with best (max) score BirdClassificationTask/Payload1_valid/labels/accuracy=0.105\n",
      "[12.0 epo]: BirdClassificationTask:[Payload0_train/labels/loss=3.10e+00, Payload1_valid/labels/accuracy=1.26e-01] model:[train/all/loss=3.10e+00, train/all/lr=1.00e-03, valid/all/loss=3.91e+00]\n",
      "Saving model at iteration 12.00 with best (max) score BirdClassificationTask/Payload1_valid/labels/accuracy=0.126\n",
      "Updated lr from 0.001 to 0.0005\n",
      "[14.0 epo]: BirdClassificationTask:[Payload0_train/labels/loss=2.62e+00, Payload1_valid/labels/accuracy=1.91e-01] model:[train/all/loss=2.62e+00, train/all/lr=5.00e-04, valid/all/loss=3.53e+00]\n",
      "Saving model at iteration 14.00 with best (max) score BirdClassificationTask/Payload1_valid/labels/accuracy=0.191\n",
      "[16.0 epo]: BirdClassificationTask:[Payload0_train/labels/loss=1.80e+00, Payload1_valid/labels/accuracy=2.07e-01] model:[train/all/loss=1.80e+00, train/all/lr=5.00e-04, valid/all/loss=3.50e+00]\n",
      "Saving model at iteration 16.00 with best (max) score BirdClassificationTask/Payload1_valid/labels/accuracy=0.207\n",
      "[18.0 epo]: BirdClassificationTask:[Payload0_train/labels/loss=1.25e+00, Payload1_valid/labels/accuracy=1.77e-01] model:[train/all/loss=1.25e+00, train/all/lr=5.00e-04, valid/all/loss=3.94e+00]\n",
      "[20.0 epo]: BirdClassificationTask:[Payload0_train/labels/loss=7.36e-01, Payload1_valid/labels/accuracy=1.98e-01] model:[train/all/loss=7.36e-01, train/all/lr=5.00e-04, valid/all/loss=3.98e+00]\n",
      "[22.0 epo]: BirdClassificationTask:[Payload0_train/labels/loss=3.68e-01, Payload1_valid/labels/accuracy=1.66e-01] model:[train/all/loss=3.68e-01, train/all/lr=5.00e-04, valid/all/loss=4.78e+00]\n",
      "[24.0 epo]: BirdClassificationTask:[Payload0_train/labels/loss=1.76e-01, Payload1_valid/labels/accuracy=2.07e-01] model:[train/all/loss=1.76e-01, train/all/lr=5.00e-04, valid/all/loss=4.70e+00]\n",
      "Updated lr from 0.0005 to 0.00025\n",
      "[26.0 epo]: BirdClassificationTask:[Payload0_train/labels/loss=5.85e-02, Payload1_valid/labels/accuracy=2.26e-01] model:[train/all/loss=5.85e-02, train/all/lr=2.50e-04, valid/all/loss=4.33e+00]\n",
      "Saving model at iteration 26.00 with best (max) score BirdClassificationTask/Payload1_valid/labels/accuracy=0.226\n",
      "[28.0 epo]: BirdClassificationTask:[Payload0_train/labels/loss=1.38e-02, Payload1_valid/labels/accuracy=2.20e-01] model:[train/all/loss=1.38e-02, train/all/lr=2.50e-04, valid/all/loss=4.37e+00]\n",
      "[30.0 epo]: BirdClassificationTask:[Payload0_train/labels/loss=9.21e-03, Payload1_valid/labels/accuracy=2.27e-01] model:[train/all/loss=9.21e-03, train/all/lr=2.50e-04, valid/all/loss=4.44e+00]\n",
      "Saving model at iteration 30.00 with best (max) score BirdClassificationTask/Payload1_valid/labels/accuracy=0.227\n",
      "[30.01 epo]: model:[train/all/lr=2.50e-04, valid/all/loss=4.44e+00] BirdClassificationTask:[Payload1_valid/labels/accuracy=2.27e-01]\n",
      "Finished training\n",
      "{'BirdClassificationTask/Payload0_train/labels/accuracy': 1.0,\n",
      " 'BirdClassificationTask/Payload2_test/labels/accuracy': 0.22833966171901968}\n",
      "Cleaning checkpoints\n"
     ]
    }
   ],
   "source": [
    "from metal.mmtl.trainer import MultitaskTrainer\n",
    "trainer = MultitaskTrainer()\n",
    "# scores = trainer.train_model(\n",
    "#     model, \n",
    "#     payloads, \n",
    "#     n_epochs=30, \n",
    "#     log_every=2,\n",
    "#     lr=0.001,\n",
    "#     progress_bar=False,\n",
    "#     lr_scheduler='reduce_on_plateau',\n",
    "#     patience = 10,\n",
    "#     checkpoint_every = 2,\n",
    "#     checkpoint_metric='BirdClassificationTask/Payload1_valid/labels/accuracy',\n",
    "#     checkpoint_metric_mode='max',\n",
    "# )\n",
    "scores = trainer.train_model(\n",
    "    model, \n",
    "    payloads, \n",
    "    n_epochs=30, \n",
    "    log_every=2,\n",
    "    lr=0.001,\n",
    "    progress_bar=False,\n",
    "    lr_scheduler='reduce_on_plateau',\n",
    "    patience = 10,\n",
    "    checkpoint_every = 2,\n",
    "    checkpoint_metric='BirdClassificationTask/Payload1_valid/labels/accuracy',\n",
    "    checkpoint_metric_mode='max',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'resnet18_lr_1e-3_patience10_shuffled_fc_separated.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see where the model struggles to make accurate predictions by sweeping over the binary attributes. We can then use these to idenitfy potentially useful slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'resnet18_lr_1e-3_patience10.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-730e089965f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mNUM_ATTRIBUTES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m312\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mattributes_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'attributes/image_attribute_labels.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resnet18_lr_1e-3_patience10.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayloads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'BirdClassificationTask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/scratch0/saelig/miniconda3/envs/slicing/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'resnet18_lr_1e-3_patience10.pt'"
     ]
    }
   ],
   "source": [
    "NUM_ATTRIBUTES = 312\n",
    "attributes_array = np.loadtxt(os.path.join(DATASET_DIR, 'attributes/image_attribute_labels.txt'), usecols=(0,1,2))\n",
    "model = torch.load('resnet18_lr_1e-3_patience10.pt')\n",
    "\n",
    "predictions = torch.tensor(model.predict(payloads[2], task_name='BirdClassificationTask'))\n",
    "print((predictions == (Y_test)).sum())\n",
    "incorrect_predictions = (predictions != Y_test).nonzero().flatten().tolist() #get indices of incorrect predictions\n",
    "print(len(incorrect_predictions))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = train_test_split[train_test_split[:,1] == 0][:,0]\n",
    "counter = [0] * NUM_ATTRIBUTES\n",
    "for id in incorrect_predictions:\n",
    "    image_id = id + 1\n",
    "    attributes_for_image = attributes_array[attributes_array[:, 0] == image_id][:,1:]\n",
    "    for i in range(len(attributes_for_image)):\n",
    "        if attributes_for_image[i,1] == 1: #attribute is present\n",
    "            counter[i] += 1\n",
    "\n",
    "\n",
    "l = list(map(lambda x: (x[0] + 1, x[1]), enumerate(counter)))\n",
    "print('(attribute id, num misclassifed images)')\n",
    "print(sorted(l, key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
