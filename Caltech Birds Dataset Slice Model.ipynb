{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import metal\n",
    "import os\n",
    "# Import other dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "os.environ['METALHOME'] = '/dfs/scratch1/saelig/slicing/metal/'\n",
    "# Set random seed for notebook\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, transform\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "opj = os.path.join\n",
    "HOME_DIR = '/dfs/scratch1/saelig/slicing/'\n",
    "DATASET_DIR = opj(HOME_DIR,'CUB_200_2011')\n",
    "IMAGES_DIR = opj(DATASET_DIR, 'images')\n",
    "TENSORS_DIR = opj(HOME_DIR, 'birds_data')\n",
    "MODELS_DIR = opj(HOME_DIR, 'birds_models')\n",
    "\n",
    "#Size of eac\n",
    "#image_list = np.loadtxt(os.path.join(DATASET_DIR, 'images.txt'), dtype=str)\n",
    "#train_test_split = np.loadtxt(os.path.join(DATASET_DIR, 'train_test_split.txt'), dtype=int)\n",
    "#labels = np.loadtxt(os.path.join(DATASET_DIR, 'image_class_labels.txt'), dtype=int)\n",
    "\n",
    "\n",
    "train_image_ids = torch.load(opj(TENSORS_DIR,'train_image_ids.pt'))\n",
    "valid_image_ids = torch.load(opj(TENSORS_DIR,'valid_image_ids.pt'))\n",
    "test_image_ids = torch.load(opj(TENSORS_DIR,'test_image_ids.pt'))\n",
    "X_train = torch.load(opj(TENSORS_DIR,'X_train.pt'))\n",
    "X_valid = torch.load(opj(TENSORS_DIR,'X_valid.pt'))\n",
    "X_test = torch.load(opj(TENSORS_DIR,'X_test.pt'))\n",
    "Y_train = torch.load(opj(TENSORS_DIR,'Y_train.pt'))\n",
    "Y_valid = torch.load(opj(TENSORS_DIR,'Y_valid.pt'))\n",
    "Y_test = torch.load(opj(TENSORS_DIR,'Y_test.pt'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the payloads. First we need to put the attribute information into an easy to deal with data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs_array = np.loadtxt(os.path.join(DATASET_DIR, 'attributes/image_attribute_labels.txt'), usecols=(0,1,2), dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a dictionary to make it easier to figure out which samples have which attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ATTRIBUTES = 312\n",
    "\n",
    "#format: <image_id>,  <attribute_id>,  <is_present>\n",
    "\n",
    "attrs_dict = {} #dict mapping attribute id to a set of image_ids that have that attribute\n",
    "\n",
    "# for attr in range(1, NUM_ATTRIBUTES + 1):\n",
    "#     temp = attrs_array[(attrs_array[:, 1] == attr) & (attrs_array[:,2] == 1)]\n",
    "#     print(temp)\n",
    "#     break\n",
    "\n",
    "for (image_id, attr_id, is_present) in attrs_array:\n",
    "    if is_present == 1:\n",
    "        if attr_id in attrs_dict:\n",
    "            attrs_dict[attr_id].add(image_id)\n",
    "        else:\n",
    "            attrs_dict[attr_id] = {image_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create payload abstraction for slices based on the binary attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.mmtl.payload import Payload\n",
    "from metal.mmtl.data import MmtlDataLoader, MmtlDataset\n",
    "from pprint import pprint\n",
    "\n",
    "payloads = []\n",
    "splits = [\"train\", \"valid\", \"test\"]\n",
    "X_splits = X_train, X_valid, X_test\n",
    "Y_splits = Y_train, Y_valid, Y_test\n",
    "\n",
    "task_name = 'BirdClassificationTask'\n",
    "labels_to_tasks = {\"labelset_gold\": task_name}\n",
    "\n",
    "for i in range(3):\n",
    "    payload_name = f\"Payload{i}_{splits[i]}\"\n",
    "    X_dict = {'data': X_splits[i]}\n",
    "    Y_dict = {'labelset_gold': Y_splits[i]}\n",
    "    \n",
    "    if splits[i] == 'train':\n",
    "        image_ids = train_image_ids\n",
    "    elif splits[i] == 'valid':\n",
    "        image_ids = valid_image_ids\n",
    "    else:\n",
    "        image_ids = test_image_ids\n",
    "    for attr_id in range(1, NUM_ATTRIBUTES + 1):\n",
    "        f = lambda x: 1 if x in attrs_dict[attr_id] else 0\n",
    "        mask = list(map(f, image_ids.tolist()))\n",
    "        if splits[i] == 'train':\n",
    "            print('Proportion of attribute {} in train set: {}'.format(attr_id, sum(mask)/len(mask)))\n",
    "        mask = torch.tensor(mask)\n",
    "        slice_labelset_name = f\"labelset:{attr_id}:pred\"\n",
    "        slice_task_name = f\"{task_name}:{attr_id}:pred\"\n",
    "        Y_dict[slice_labelset_name] = mask * Y_splits[i]\n",
    "        labels_to_tasks[slice_labelset_name] = task_name\n",
    "        \n",
    "        mask[mask == 0] = 2 #to follow Metal convention\n",
    "        slice_labelset_name = f\"labelset:{attr_id}:ind\"\n",
    "        slice_task_name = f\"{task_name}:{attr_id}:ind\"\n",
    "        Y_dict[slice_labelset_name] = mask \n",
    "        labels_to_tasks[slice_labelset_name] = None\n",
    "        \n",
    "    \n",
    "    dataset = MmtlDataset(X_dict, Y_dict)\n",
    "    data_loader = MmtlDataLoader(dataset, batch_size=32)\n",
    "    payload = Payload(payload_name, data_loader, labels_to_tasks, splits[i])\n",
    "    payloads.append(payload)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(opj(MODELS_DIR,'resnet18_lr_1e-3_patience10.pt')) #achieves 17% accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_per_slice = model.score(payloads[1], metrics=[]) #score on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('19', 0.0), ('34', 0.0), ('49', 0.0), ('115', 0.0), ('130', 0.0), ('138', 0.0), ('144', 0.0), ('145', 0.0), ('162', 0.0), ('171', 0.0), ('177', 0.0), ('267', 0.0), ('271', 0.0), ('281', 0.0), ('286', 0.0), ('287', 0.0), ('175', 0.05555555555555555), ('242', 0.05660377358490566), ('190', 0.06521739130434782), ('246', 0.06557377049180328), ('87', 0.06666666666666667), ('17', 0.07017543859649122), ('126', 0.07142857142857142), ('176', 0.07142857142857142), ('129', 0.07692307692307693), ('235', 0.08), ('32', 0.08064516129032258), ('140', 0.08333333333333333), ('279', 0.08333333333333333), ('301', 0.08333333333333333), ('66', 0.08620689655172414), ('56', 0.08641975308641975), ('256', 0.08823529411764706), ('128', 0.09090909090909091), ('192', 0.09090909090909091), ('252', 0.09090909090909091), ('94', 0.09166666666666666), ('81', 0.09574468085106383), ('47', 0.0967741935483871), ('160', 0.0967741935483871), ('274', 0.09917355371900827), ('89', 0.1), ('135', 0.1), ('161', 0.1), ('178', 0.1), ('302', 0.1), ('263', 0.10043668122270742), ('41', 0.10236220472440945), ('54', 0.1024390243902439), ('308', 0.10273972602739725), ('141', 0.10344827586206896), ('205', 0.10344827586206896), ('111', 0.10480349344978165), ('75', 0.1048951048951049), ('24', 0.1050228310502283), ('149', 0.10526315789473684), ('212', 0.10552763819095477), ('73', 0.10674157303370786), ('182', 0.1076923076923077), ('107', 0.10810810810810811), ('243', 0.10810810810810811), ('167', 0.1095890410958904), ('158', 0.10964912280701754), ('120', 0.1111111111111111), ('299', 0.11155378486055777), ('278', 0.11173184357541899), ('247', 0.112), ('199', 0.11214953271028037), ('39', 0.11413043478260869), ('50', 0.11428571428571428), ('239', 0.11458333333333333), ('203', 0.115), ('265', 0.11538461538461539), ('169', 0.116751269035533), ('60', 0.11739130434782609), ('154', 0.11739130434782609), ('11', 0.11764705882352941), ('30', 0.11799410029498525), ('197', 0.11827956989247312), ('218', 0.11904761904761904), ('57', 0.11920529801324503), ('4', 0.12), ('304', 0.12), ('295', 0.12048192771084337), ('222', 0.12087912087912088), ('137', 0.12121212121212122), ('208', 0.12121212121212122), ('64', 0.12152777777777778), ('7', 0.12179487179487179), ('228', 0.12371134020618557), ('35', 0.125), ('207', 0.125), ('15', 0.12534818941504178), ('26', 0.12585034013605442), ('254', 0.12605042016806722), ('310', 0.1282051282051282), ('280', 0.12844036697247707), ('188', 0.12857142857142856), ('173', 0.13043478260869565), ('45', 0.13100436681222707), ('233', 0.13114754098360656), ('122', 0.13131313131313133), ('85', 0.13274336283185842), ('77', 0.13333333333333333), ('88', 0.13333333333333333), ('226', 0.13333333333333333), ('277', 0.13333333333333333), ('210', 0.1341991341991342), ('133', 0.13447432762836187), ('147', 0.13513513513513514), ('257', 0.13636363636363635), ('184', 0.13656387665198239), ('9', 0.13793103448275862), ('113', 0.13793103448275862), ('276', 0.13953488372093023), ('100', 0.14), ('250', 0.14144736842105263), ('102', 0.1423841059602649), ('28', 0.14285714285714285), ('86', 0.14285714285714285), ('136', 0.14285714285714285), ('217', 0.14285714285714285), ('232', 0.14285714285714285), ('268', 0.14285714285714285), ('303', 0.14285714285714285), ('248', 0.14444444444444443), ('285', 0.14473684210526316), ('238', 0.14516129032258066), ('195', 0.14624505928853754), ('311', 0.14715719063545152), ('118', 0.14772727272727273), ('150', 0.14772727272727273), ('98', 0.14814814814814814), ('251', 0.14814814814814814), ('76', 0.14958448753462603), ('52', 0.15), ('224', 0.15), ('216', 0.15053763440860216), ('117', 0.15163934426229508), ('229', 0.15254237288135594), ('127', 0.1527777777777778), ('291', 0.1527777777777778), ('214', 0.1532258064516129), ('27', 0.15384615384615385), ('48', 0.15384615384615385), ('270', 0.15384615384615385), ('293', 0.15384615384615385), ('236', 0.15397923875432526), ('5', 0.15492957746478872), ('213', 0.15497076023391812), ('101', 0.15508021390374332), ('BirdClassificationTask/Payload1_valid/labelset_gold/accuracy', 0.15512927439532945), ('290', 0.15520628683693516), ('204', 0.15568862275449102), ('116', 0.15625), ('152', 0.15625), ('46', 0.15760869565217392), ('58', 0.15765765765765766), ('170', 0.15789473684210525), ('269', 0.15838509316770186), ('289', 0.1590909090909091), ('103', 0.16030534351145037), ('95', 0.16129032258064516), ('146', 0.16205128205128205), ('16', 0.16216216216216217), ('244', 0.16236162361623616), ('194', 0.16346153846153846), ('309', 0.16374269005847952), ('219', 0.1640625), ('240', 0.16455696202531644), ('284', 0.16463414634146342), ('180', 0.16517857142857142), ('8', 0.1661721068249258), ('55', 0.16640986132511557), ('18', 0.16666666666666666), ('33', 0.16666666666666666), ('68', 0.16666666666666666), ('92', 0.16666666666666666), ('153', 0.16666666666666666), ('159', 0.16666666666666666), ('201', 0.16666666666666666), ('259', 0.16666666666666666), ('266', 0.16666666666666666), ('297', 0.16666666666666666), ('245', 0.16690856313497823), ('261', 0.16759776536312848), ('78', 0.16831683168316833), ('71', 0.1686746987951807), ('112', 0.1696969696969697), ('132', 0.17028985507246377), ('221', 0.17040358744394618), ('31', 0.17094017094017094), ('165', 0.17105263157894737), ('249', 0.17105263157894737), ('96', 0.17117117117117117), ('305', 0.1717948717948718), ('97', 0.1724137931034483), ('312', 0.17341040462427745), ('51', 0.17391304347826086), ('67', 0.17391304347826086), ('164', 0.1741424802110818), ('241', 0.1747787610619469), ('209', 0.17575757575757575), ('255', 0.17714285714285713), ('151', 0.1791044776119403), ('230', 0.1794871794871795), ('10', 0.18032786885245902), ('40', 0.18181818181818182), ('65', 0.18181818181818182), ('258', 0.18181818181818182), ('288', 0.18181818181818182), ('237', 0.182648401826484), ('104', 0.18478260869565216), ('260', 0.18501170960187355), ('37', 0.18613138686131386), ('275', 0.1863799283154122), ('294', 0.1864406779661017), ('215', 0.18666666666666668), ('21', 0.18773946360153257), ('300', 0.18811881188118812), ('25', 0.18840579710144928), ('231', 0.189873417721519), ('179', 0.1903485254691689), ('42', 0.19047619047619047), ('74', 0.19047619047619047), ('12', 0.19230769230769232), ('174', 0.19402985074626866), ('91', 0.1955128205128205), ('306', 0.1984732824427481), ('62', 0.2), ('108', 0.2), ('114', 0.2), ('148', 0.2), ('163', 0.2), ('186', 0.2), ('191', 0.2), ('282', 0.2), ('283', 0.2), ('296', 0.2), ('70', 0.20058997050147492), ('105', 0.2013888888888889), ('36', 0.2017353579175705), ('189', 0.20588235294117646), ('2', 0.20689655172413793), ('20', 0.20689655172413793), ('61', 0.20833333333333334), ('155', 0.20833333333333334), ('3', 0.21052631578947367), ('183', 0.21052631578947367), ('79', 0.21153846153846154), ('22', 0.21428571428571427), ('69', 0.21428571428571427), ('181', 0.21428571428571427), ('206', 0.21428571428571427), ('264', 0.21428571428571427), ('273', 0.21428571428571427), ('121', 0.21875), ('1', 0.2222222222222222), ('6', 0.2222222222222222), ('44', 0.22727272727272727), ('168', 0.22727272727272727), ('139', 0.23076923076923078), ('185', 0.23076923076923078), ('223', 0.23076923076923078), ('234', 0.23076923076923078), ('292', 0.23333333333333334), ('59', 0.23529411764705882), ('220', 0.23809523809523808), ('38', 0.2413793103448276), ('13', 0.25), ('43', 0.25), ('83', 0.25), ('109', 0.25), ('142', 0.25), ('172', 0.25), ('193', 0.25), ('200', 0.25), ('202', 0.25), ('106', 0.25925925925925924), ('253', 0.2608695652173913), ('80', 0.2619047619047619), ('99', 0.2619047619047619), ('131', 0.2631578947368421), ('82', 0.26666666666666666), ('90', 0.26666666666666666), ('110', 0.2727272727272727), ('124', 0.2857142857142857), ('187', 0.2916666666666667), ('123', 0.29411764705882354), ('14', 0.3125), ('29', 0.3125), ('196', 0.3181818181818182), ('198', 0.3181818181818182), ('166', 0.325), ('134', 0.32608695652173914), ('53', 0.3333333333333333), ('63', 0.3333333333333333), ('72', 0.3333333333333333), ('156', 0.3333333333333333), ('157', 0.3333333333333333), ('225', 0.3333333333333333), ('227', 0.3333333333333333), ('298', 0.3333333333333333), ('307', 0.3333333333333333), ('119', 0.3488372093023256), ('125', 0.35), ('262', 0.35), ('23', 0.375), ('211', 0.3902439024390244), ('93', 0.4117647058823529), ('84', 0.5), ('272', 0.5), ('143', 1.0)]\n"
     ]
    }
   ],
   "source": [
    "accs_per_slice_list = list(accs_per_slice.items())\n",
    "accs_per_slice_list = list(map(lambda p: (p[0].split(':')[1], p[1]) if ':' in p[0] else p, accs_per_slice_list))\n",
    "print(sorted(accs_per_slice_list, key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
